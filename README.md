<h1 align="center">
  <img src="https://readme-typing-svg.herokuapp.com?font=JetBrains+Mono&weight=700&size=28&pause=1000&color=00FFAA&center=true&vCenter=true&width=600&lines=ML+Engineer+%7C+Production+Pipelines;PyTorch+%E2%86%92+ONNX+%E2%86%92+CoreML+%E2%86%92+Deploy;Building+fast+%26+efficient+ML+systems" alt="Typing SVG" />
</h1>

<p align="center">
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white" />
  <img src="https://img.shields.io/badge/ONNX-005CED?style=for-the-badge&logo=onnx&logoColor=white" />
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white" />
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" />
</p>

---

### About Me

I'm an ML Engineer focused on **taking models from training to production**.
I build end-to-end pipelines that are fast, optimized, and deployment-ready.

```python
class SandQueen1111:
    role = "ML Engineer"
    focus = ["Model Optimization", "Production Deployment", "Edge Inference"]
    stack = {
        "ml":       ["PyTorch", "ONNX Runtime", "CoreML", "TensorRT"],
        "backend":  ["FastAPI", "Python", "Docker", "REST APIs"],
        "optimize": ["INT8/FP16 Quantization", "Mixed Precision (AMP)"],
        "deploy":   ["Apple Silicon (MPS)", "NVIDIA GPU", "ONNX Runtime"],
    }
    motto = "Ship models, not notebooks."
```

---

### Key Metrics

| Model Accuracy | Inference Latency | Size Reduction | Throughput |
|:-:|:-:|:-:|:-:|
| **96.8%** | **4.2ms** | **74%** | **238 img/s** |

*EfficientNet-B0 · Transfer Learning · INT8 Quantization · ONNX Runtime*

---

### Featured Projects

| Project | Description | Tech |
|---------|-------------|------|
| **pytorch-onnx-pipeline** | End-to-end ML pipeline: Training, ONNX Export, INT8, FastAPI | PyTorch, ONNX, FastAPI |
| **ml-model-optimizer** | Automated model optimization and benchmark toolkit | ONNX, Quantization |
| **realtime-classifier** | Real-time image classification with webcam and ONNX Runtime | OpenCV, ONNX Runtime |

---

### Tech Stack

**Machine Learning and Deep Learning**
```
PyTorch · ONNX Runtime · CoreML · TensorRT · Hugging Face
Transfer Learning · EfficientNet · ResNet · Model Distillation
```

**Optimization and Deployment**
```
INT8/FP16 Quantization · Mixed Precision (AMP) · Dynamic Batching
FastAPI · Docker · REST APIs · Apple Silicon (MPS) · CUDA
```

**Tools and Infrastructure**
```
Python · Git · Linux · NumPy · Pandas · Jupyter
CI/CD · Benchmarking · Profiling · Monitoring
```

---

### Pipeline Architecture

```
Data --> Training --> Export --> Optimize --> Deploy
         (AMP)       (ONNX)    (INT8)      (FastAPI)
       EfficientNet  Opset 17  74% smaller  P99: 8.1ms
       CosineAnneal            3x faster    238 img/s
```

---

### Contact

- Portfolio: [SandQueen1111.github.io](https://SandQueen1111.github.io)
- Location: Germany | Open to remote and on-site

---

<p align="center"><em>"Ship models, not notebooks."</em></p>
